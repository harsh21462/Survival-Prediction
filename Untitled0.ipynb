{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nycKOMsbXG0U",
        "outputId": "44caf97d-65bc-46e3-e7ce-ba73ade0a37a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9473684210526315\n",
            "XGBoost Accuracy: 0.9210526315789473\n",
            "Random Forest Feature Importances: [0.03037424 0.0033626  0.00433204 0.03277959 0.0049795  0.00517106\n",
            " 0.00145364 0.0065065  0.0123834  0.0102862  0.00616586 0.01425669\n",
            " 0.00457834 0.00619193 0.00847726 0.00804949 0.0023976  0.00515442\n",
            " 0.00136434 0.00880637 0.00670069 0.01166372 0.0350538  0.00619054\n",
            " 0.00733283 0.06370247 0.00253169 0.07904502 0.05147873 0.02694688\n",
            " 0.04067065 0.03718008 0.02457732 0.05453951 0.00733154 0.34505695\n",
            " 0.0038764  0.00731243 0.00878417 0.00295351]\n",
            "XGBoost Feature Importances: [0.0168509  0.         0.         0.01455483 0.         0.\n",
            " 0.         0.         0.00954438 0.07367864 0.         0.03822138\n",
            " 0.         0.00306477 0.05869889 0.         0.         0.01028652\n",
            " 0.         0.00495794 0.         0.         0.00461293 0.\n",
            " 0.         0.1242661  0.         0.         0.02872669 0.02995251\n",
            " 0.         0.02050513 0.01003553 0.00240751 0.         0.54963535\n",
            " 0.         0.         0.         0.        ]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import xgboost as xgb\n",
        "\n",
        "df = pd.read_csv('csv_result-bone-marrow.csv')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create an instance of the OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse=False, drop='first')  # drop='first' to avoid multicollinearity\n",
        "\n",
        "# Fit and transform the categorical column\n",
        "encoded_colors = encoder.fit_transform(df[['Disease']])\n",
        "\n",
        "\n",
        "# Create a DataFrame from the encoded values\n",
        "encoded_df = pd.DataFrame(encoded_colors, columns=encoder.get_feature_names_out(['Disease']))\n",
        "\n",
        "# Concatenate the original DataFrame and the one-hot encoded DataFrame\n",
        "final_df = pd.concat([df, encoded_df], axis=1)\n",
        "\n",
        "# Drop the original 'Color' column if needed\n",
        "final_df = final_df.drop('Disease', axis=1)\n",
        "\n",
        "final_df = final_df.replace('?',np.nan)\n",
        "\n",
        "# null_count = final_df.isnull().sum().sum()\n",
        "# print(\"Number of rows with null values:\", null_count)\n",
        "\n",
        "\n",
        "#NaN values ko hatana\n",
        "# Convert columns to numeric (if needed)\n",
        "final_df = final_df.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "for column in final_df.columns:\n",
        "    final_df[column].fillna(final_df[column].mean(), inplace=True)\n",
        "\n",
        "# final_df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x = final_df.drop('survival_status',axis=1)\n",
        "y = final_df['survival_status']\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test ,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=100)\n",
        "\n",
        "\n",
        "# df.dtypes\n",
        "\n",
        "\n",
        "# Feature enginering done Now Feature selection\n",
        "\n",
        "#1) dropping constant features\n",
        "\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "var_thres = VarianceThreshold(threshold=0)\n",
        "var_thres.fit(x_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#calculating constant coloumn\n",
        "constant_columns = [column for column in x_train.columns\n",
        "                    if column not in x_train.columns[var_thres.get_support()]]\n",
        "\n",
        "# print(len(constant_columns))\n",
        "\n",
        "x_train.drop(constant_columns,axis = 1)\n",
        "\n",
        "\n",
        "\n",
        "#2) dropping features using Pearson Correlation\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# final_df.info()\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "random_forest = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "random_forest.fit(x_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = random_forest.predict(x_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Get Random Forest feature importances\n",
        "rf_feature_importances = random_forest.feature_importances_\n",
        "\n",
        "#xgboost\n",
        "\n",
        "\n",
        "\n",
        "# Initialize the XGBoost classifier\n",
        "xgb_classifier = xgb.XGBClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "xgb_classifier.fit(x_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = xgb_classifier.predict(x_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"XGBoost Accuracy:\", accuracy)\n",
        "\n",
        "# Get XGBoost feature importances\n",
        "xgb_feature_importances = xgb_classifier.feature_importances_\n",
        "\n",
        "\n",
        "# Display feature importances\n",
        "print(\"Random Forest Feature Importances:\", rf_feature_importances)\n",
        "print(\"XGBoost Feature Importances:\", xgb_feature_importances)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}